{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../experiments\")\n",
    "\n",
    "from experiments.constants import * \n",
    "from experiments.utils import *\n",
    "\n",
    "from random import randint\n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TGT = SPANISH, BASQUE\n",
    "LP_FOLDER = f\"/netscratch/falcao/data/appraise-batches/{SRC}-{TGT}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "_task_definition = OrderedDict({\n",
    "    \"TGT\": 80,\n",
    "    \"CHK\": 0,\n",
    "    \"REF\": 10,\n",
    "    \"BAD\": 10,\n",
    "})\n",
    "\n",
    "BATCHES_FILENAME = \"batches.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_DEFINITION = \":\".join(map(str, _task_definition.values()))\n",
    "SRC_FILE = f\"{LP_FOLDER}/src.{SRC}\"\n",
    "REF_FILE = f\"{LP_FOLDER}/ref.{TGT}\"\n",
    "SYSTEMS_FOLDER = f\"{LP_FOLDER}/systems/\"\n",
    "BATCHES_PATH = f\"{LP_FOLDER}/{BATCHES_FILENAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using task definition: (80, 0, 10, 10)\n",
      "Loaded 288 source segments\n",
      "Loaded 288 reference segments\n",
      "character_based = False\n",
      "Loaded 288 system gtrans-fake.txt segments\n",
      "Loaded 288 system mstrans-fake.txt segments\n",
      "Creating /netscratch/falcao/data/appraise-batches/es-eu/batches.json.segments ... OK\n",
      "Missing items is 64/80/576\n",
      "Added 64 missing items rotating keys\n",
      "Total number of batches is 8\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [12, 46, 1, 5, 24, 13, 35, 26, 39, 15]\n",
      "bad_ids: [6, 16, 41, 47, 0, 2, 22, 14, 18, 44]\n",
      "empty_slots [53, 54, 57, 58, 59, 60, 61, 67, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 95, 98, 99]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [10, 31, 11, 44, 48, 41, 43, 39, 26, 12]\n",
      "bad_ids: [32, 24, 5, 4, 14, 28, 47, 15, 3, 49]\n",
      "empty_slots [50, 51, 52, 56, 57, 58, 59, 63, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 79, 80, 83, 84, 85, 86, 87, 88, 90, 92, 95, 96]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [7, 17, 46, 18, 31, 4, 13, 23, 6, 25]\n",
      "bad_ids: [48, 30, 15, 29, 3, 26, 27, 1, 35, 16]\n",
      "empty_slots [50, 52, 55, 58, 59, 60, 61, 62, 64, 69, 70, 71, 72, 74, 78, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [41, 9, 31, 26, 42, 40, 23, 11, 28, 22]\n",
      "bad_ids: [13, 30, 39, 14, 16, 49, 32, 4, 3, 25]\n",
      "empty_slots [50, 51, 52, 55, 56, 57, 58, 60, 62, 65, 67, 68, 69, 70, 71, 74, 77, 79, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [2, 5, 7, 40, 16, 42, 43, 35, 23, 48]\n",
      "bad_ids: [8, 13, 22, 31, 34, 17, 30, 49, 9, 46]\n",
      "empty_slots [50, 51, 53, 54, 56, 60, 61, 62, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 82, 83, 86, 87, 88, 89, 91, 94, 95, 97]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [44, 22, 38, 18, 35, 33, 19, 21, 6, 5]\n",
      "bad_ids: [17, 23, 29, 34, 28, 20, 41, 36, 9, 8]\n",
      "empty_slots [50, 51, 52, 53, 54, 57, 60, 61, 62, 63, 64, 65, 66, 74, 75, 76, 77, 80, 81, 82, 87, 89, 90, 92, 93, 95, 96, 97, 98, 99]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [4, 18, 15, 42, 45, 21, 22, 14, 48, 44]\n",
      "bad_ids: [17, 37, 29, 39, 32, 0, 16, 41, 6, 35]\n",
      "empty_slots [51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 69, 70, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 86, 88, 90, 93, 96, 97, 99]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "0 10 10\n",
      "chk_items: 0\n",
      "ref_items: 10\n",
      "bad_items: 10\n",
      "chk_ids: []\n",
      "ref_ids: [19, 16, 41, 31, 15, 2, 12, 9, 5, 14]\n",
      "bad_ids: [37, 3, 11, 26, 48, 45, 36, 7, 24, 39]\n",
      "empty_slots [50, 51, 54, 56, 58, 60, 63, 67, 68, 70, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 84, 85, 88, 90, 92, 93, 94, 96, 97, 99]\n",
      "len(batch_items): 100\n",
      "len(batch_items) == None: 0\n",
      "Creating /netscratch/falcao/data/appraise-batches/es-eu/batches.json ... OK\n"
     ]
    }
   ],
   "source": [
    "# call the command from bash but using variables set in Python\n",
    "! python manage.py CreateDirectAssessmentData \\\n",
    "    100 \\\n",
    "    $SRC.code3 \\\n",
    "    $TGT.code3 \\\n",
    "    $LP_FOLDER/src.$SRC \\\n",
    "    $LP_FOLDER/ref.$TGT \\\n",
    "    $SYSTEMS_FOLDER \\\n",
    "    $BATCHES_PATH \\\n",
    "    --task-definition $TASK_DEFINITION \\\n",
    "    --required-annotations 3 \\\n",
    "    --source-based \\\n",
    "    --create-ids \\\n",
    "    --all-batches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "CAMPAIGN_NAME = \"test1item\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = {\n",
    "    \"CAMPAIGN_URL\": \"http://127.0.0.1:8000/dashboard/sso/\",\n",
    "    \"CAMPAIGN_NAME\": CAMPAIGN_NAME,\n",
    "    \"CAMPAIGN_KEY\": CAMPAIGN_NAME,\n",
    "    \"CAMPAIGN_NO\": randint(0,100),\n",
    "    \"REDUNDANCY\": 1,\n",
    "\n",
    "    \"TASKS_TO_ANNOTATORS\": [\n",
    "        [ SRC.code3, TGT.code3, \"uniform\", 1, 1 ]\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(manifest[\"TASKS_TO_ANNOTATORS\"]) == list and type(manifest[\"TASKS_TO_ANNOTATORS\"][0]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANIFEST_PATH = f\"{LP_FOLDER}/manifest.json\"\n",
    "\n",
    "with open(MANIFEST_PATH, mode=\"w+\") as f:\n",
    "    json.dump(manifest, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON manifest path: '/netscratch/falcao/data/appraise-batches/es-eu/manifest.json'\n",
      "CSV output path: None\n",
      "Excel output path: None\n",
      "No task type found in the manifest file, assuming it is \"Direct\". If this is incorrect, define \"TASK_TYPE\" in the manifest file.\n",
      "### Running InitCampaign\n",
      "All languages: [('spa', 'eus')]\n",
      "Identified superuser: falcao\n",
      "Processed Market/Metadata instances\n",
      "### Creating a new campaign\n",
      "- '/netscratch/falcao/data/appraise-batches/es-eu/batches.json'\n",
      "Batch: /netscratch/falcao/data/appraise-batches/es-eu/batches.json\n",
      "  Market: spa_eus_test1item\n",
      "  Metadata: spa->eus/test1item[\"1.0\"]\n",
      "Uploaded file name: Batches/batches_H2j8u8J.json\n",
      "Campaign name: test1item\n",
      "### Running validatecampaigndata\n",
      "Campaign name: test1item\n",
      "Batch name: Batches/batches_H2j8u8J.json\n",
      "Validated 1 batches\n",
      "### Running ProcessCampaignData\n",
      "Batches/batches_H2j8u8J.json 1\n",
      "15 gtrans-fake.txt\n",
      "195 b'[gtrans] Goizeko lehen orduan anaiak agertu ziren duin-itxurak eginez, tronpeta erlastuen zarataz inguraturik, eta beren konkistetan botikak pixkanaka kendu, eta psikiatriara bueltatu lagundurik.'\n",
      "0:00:00.001543\n",
      "Campaign activated\n",
      "### Running UpdateEvalDataModels\n",
      "\n",
      "[UpdateEvalDataModels.py]\n",
      "\n",
      "\n",
      "[INIT]\n",
      "\n",
      "Processing DirectAssessmentTask/DirectAssessmentResult/TextPair\n",
      "  Processed DirectAssessmentResult instances 0:00:00.002373\n",
      "  Identified bad DirectAssessmentResult instances 0\n",
      "  Processed DirectAssessmentTask instances 0:00:00.002681\n",
      "  Processed TextPair instances 0:00:00.003444\n",
      "  Processed related DirectAssessmentTask instances 0:00:00.002875\n",
      "Processing DirectAssessmentContextTask/DirectAssessmentContextResult/TextPairWithContext\n",
      "  Processed DirectAssessmentContextResult instances 0:00:00.002393\n",
      "  Identified bad DirectAssessmentContextResult instances 0\n",
      "  Processed DirectAssessmentContextTask instances 0:00:00.002486\n",
      "  Processed TextPairWithContext instances 0:00:00.002650\n",
      "  Processed related DirectAssessmentContextTask instances 0:00:00.002993\n",
      "Processing DirectAssessmentDocumentTask/DirectAssessmentDocumentResult/TextPairWithContext\n",
      "  Processed DirectAssessmentDocumentResult instances 0:00:00.002409\n",
      "  Identified bad DirectAssessmentDocumentResult instances 0\n",
      "  Processed DirectAssessmentDocumentTask instances 0:00:00.002531\n",
      "  Processed TextPairWithContext instances 0:00:00.002618\n",
      "  Processed related DirectAssessmentDocumentTask instances 0:00:00.002832\n",
      "Processing MultiModalAssessmentTask/MultiModalAssessmentResult/TextPairWithImage\n",
      "  Processed MultiModalAssessmentResult instances 0:00:00.002437\n",
      "  Identified bad MultiModalAssessmentResult instances 0\n",
      "  Processed MultiModalAssessmentTask instances 0:00:00.002465\n",
      "  Processed TextPairWithImage instances 0:00:00.003195\n",
      "  Processed related MultiModalAssessmentTask instances 0:00:00.003220\n",
      "Processing PairwiseAssessmentTask/PairwiseAssessmentResult/TextSegmentWithTwoTargets\n",
      "  Processed PairwiseAssessmentResult instances 0:00:00.002444\n",
      "  Identified bad PairwiseAssessmentResult instances 0\n",
      "  Processed PairwiseAssessmentTask instances 0:00:00.002462\n",
      "  Processed TextSegmentWithTwoTargets instances 0:00:00.002528\n",
      "  Processed related PairwiseAssessmentTask instances 0:00:00.002809\n",
      "Processing PairwiseAssessmentDocumentTask/PairwiseAssessmentDocumentResult/TextSegmentWithTwoTargetsWithContext\n",
      "  Processed PairwiseAssessmentDocumentResult instances 0:00:00.002419\n",
      "  Identified bad PairwiseAssessmentDocumentResult instances 0\n",
      "  Processed PairwiseAssessmentDocumentTask instances 0:00:00.002475\n",
      "  Processed TextSegmentWithTwoTargetsWithContext instances 0:00:00.002620\n",
      "  Processed related PairwiseAssessmentDocumentTask instances 0:00:00.002863\n",
      "Processing DataAssessmentTask/DataAssessmentResult/TextPairWithDomain\n",
      "  Processed DataAssessmentResult instances 0:00:00.002305\n",
      "  Identified bad DataAssessmentResult instances 0\n",
      "  Processed DataAssessmentTask instances 0:00:00.002456\n",
      "  Processed TextPairWithDomain instances 0:00:00.002541\n",
      "  Processed related DataAssessmentTask instances 0:00:00.002840\n",
      "Processed MultiModalAssessmentTask instances 0:00:00.002101\n",
      "Processed TextPairWithImage instances 0:00:00.002561\n",
      "Processed related MultiModalAssessmentTask instances 0:00:00.002450\n",
      "\n",
      "[DONE]\n",
      "\n",
      "### Running init_campaign again\n",
      "All languages: [('spa', 'eus')]\n",
      "Identified superuser: falcao\n",
      "Processed Market/Metadata instances\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "! python manage.py StartNewCampaign \\\n",
    "    $MANIFEST_PATH \\\n",
    "    --batches-json $BATCHES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "n_sents = 388\n",
    "n_systems = 2\n",
    "\n",
    "n_tgt, n_chk, n_ref, n_bad = _task_definition.values()\n",
    "n_batches = ceil(n_sents * n_systems / n_tgt)\n",
    "\n",
    "n_control_total = n_batches * (n_chk + n_ref + n_bad)\n",
    "\n",
    "(n_sents * n_systems) + n_control_total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
